from google.adk import Agent
from google.adk.models import Gemini, BaseLlm
from google.adk.models.llm_response import LlmResponse
from google.adk.models.llm_request import LlmRequest
from google.genai import types
from typing import AsyncGenerator
import google.generativeai as genai_legacy
from .tools import (

    parse_resume_tool,
    semantic_similarity_tool,
    keyword_match_tool,
    ats_checker_tool,
    scoring_tool,
    latex_builder_tool
)
import os


# Define the Gemini model configuration
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyDBph_Z3ZqGUgWs9cJMzj1vF-U7R-Am8I0")







class MockGemini(BaseLlm):
    """
    A Mock LLM for testing when no API key is provided.
    """
    model: str = "mock-gemini"

    async def generate_content_async(
        self, llm_request: "LlmRequest", stream: bool = False
    ) -> AsyncGenerator[LlmResponse, None]:
        last_msg = ""
        if llm_request.contents:
            last_part = llm_request.contents[-1].parts[0]
            if last_part.text:
                last_msg = last_part.text.lower()
            else:
                last_msg = "tool_result"
        
        if "remove these **" in last_msg or "beautfull" in last_msg:
            text = """### Key Observations & Missing Elements:

1. **Core Languages:** The JD explicitly requires experience in **C++, Java, or Python**. These are currently missing from your profile.
2. **Infrastructure & Systems:** Showcase your experience with **distributed systems and storage architecture**.
3. **Technical Depth:** Highlight your proficiency in **data structures and software test engineering**.
4. **Experience Gap:** Shift focus from campus roles to **technical projects and AI agent development**.

I have implemented these suggestions in your optimized profile below! Would you like me to rebuild your resume now?"""
        elif "rebuild" in last_msg or "resume" in last_msg:
            text = "I've analyzed your profiles and the job description. I'm ready to rebuild your optimized resume with the new skills highlighted. Should I use the **Professional Classic** template?"
        else:
            text = """### Key Observations & Missing Elements:

1. **System Design**: Your profile lacks explicit experience in **high-concurrency distributed systems**, which is critical for modern Senior roles.
2. **Cloud Infrastructure**: While you have strong Python skills, adding **AWS/GCP orchestration** details would significantly boost your ATS score.
3. **Low-Level Languages**: Mentioning **C++ or Rust** project experience would distinguish you from the campus-level competition.

I can help you analyze your resume further or **rebuild** a LaTeX optimized version with these improvements! What would you like to do first?"""



        response = LlmResponse(
            content=types.Content(role="model", parts=[types.Part(text=text)]),
            partial=False
        )
        yield response


class LegacyGemini(BaseLlm):
    """
    Experimental: Uses the legacy google.generativeai SDK for keys 
    that might not be fully configured for the new SDK.
    """
    model: str = "gemini-flash-lite-latest"
    api_key: str
    system_instruction: str = ""
    tools: list = []

    def __init__(self, **data):
        super().__init__(**data)
        genai_legacy.configure(api_key=self.api_key)
        self._legacy_model = genai_legacy.GenerativeModel(
            self.model,
            system_instruction=self.system_instruction,
            tools=self.tools
        )

    async def generate_content_async(
        self, llm_request: "LlmRequest", stream: bool = False
    ) -> AsyncGenerator[LlmResponse, None]:
        # Convert ADK contents to Legacy SDK format using dictionaries
        legacy_contents = []
        for content in llm_request.contents:
            parts = []
            for p in content.parts:
                if p.text:
                    parts.append({"text": p.text})
                elif p.function_call:
                    parts.append({
                        "function_call": {
                            "name": p.function_call.name,
                            "args": dict(p.function_call.args)
                        }
                    })
                elif p.function_response:
                    parts.append({
                        "function_response": {
                            "name": p.function_response.name,
                            "response": dict(p.function_response.response)
                        }
                    })
            
            legacy_contents.append({
                "role": "user" if content.role == "user" else "model",
                "parts": parts
            })
        
        # Call legacy SDK with full conversation history
        response = self._legacy_model.generate_content(legacy_contents)

        
        parts = []
        if response.candidates and response.candidates[0].content.parts:
            for p in response.candidates[0].content.parts:
                if p.text:
                    parts.append(types.Part(text=p.text))
                if hasattr(p, 'function_call') and p.function_call:
                    parts.append(types.Part(
                        function_call=types.FunctionCall(
                            name=p.function_call.name,
                            args=dict(p.function_call.args)
                        )
                    ))

        yield LlmResponse(
            content=types.Content(role="model", parts=parts),
            partial=False
        )



from typing import Union

class FallbackGemini(BaseLlm):
    """
    Attempts use of real Gemini (Modern or Legacy), falls back to MockGemini on error.
    """
    real_model: Union[Gemini, LegacyGemini]
    mock_model: MockGemini
    model: str = "fallback-gemini"

    async def generate_content_async(
        self, llm_request: "LlmRequest", stream: bool = False
    ) -> AsyncGenerator[LlmResponse, None]:
        last_text = []
        has_tool_call = False
        try:
            # Try real model
            async for resp in self.real_model.generate_content_async(llm_request, stream):
                if resp.content and resp.content.parts:
                    for part in resp.content.parts:
                        if part.text:
                            last_text.append(part.text)
                        if part.function_call:
                            has_tool_call = True
                yield resp
            
            # If we got absolutely no text and no tool call after success, trigger mock as failsafe
            if not "".join(last_text).strip() and not has_tool_call:
                raise ValueError("No text or tool call returned from live model")

        except Exception as e:
            # Fallback to mock - silently for demo purposes
            print(f"[FallbackGemini] Error hit: {e}") 
            async for resp in self.mock_model.generate_content_async(llm_request, stream):
                yield resp






def get_resume_agent():
    """
    Initializes and returns the Google ADK Agent for resume building.
    Uses FallbackGemini to automatically switch to Mock Mode on error.
    """
    
    # Set the environment variable for google-genai client
    # If the key is the placeholder, the live model will likely fail immediately and trigger fallback
    os.environ["GOOGLE_API_KEY"] = GEMINI_API_KEY
    
    instruction = """
        You are an elite ATS-optimized Resume Consultant AI. Your mission is to WOW users with immediate, actionable insights.

        CRITICAL WORKFLOW:
        1. **When a resume file is uploaded**: IMMEDIATELY call parse_resume_tool to extract the text. Do NOT ask permission.
        2. **After parsing**: If the user hasn't provided a Job Description (JD), ask: "Please provide the Job Description you're targeting, or I'll analyze against a Senior Software Engineer role."
        3. **Once you have both resume + JD**: 
           - Call semantic_similarity_tool to compare resume vs JD
           - Call keyword_match_tool to find missing keywords
           - Call ats_checker_tool for compliance analysis
           - Call scoring_tool to generate the final ATS score
        4. **Present results** in this exact format:
           ```
           ### ðŸŽ¯ ATS Analysis Complete
           **Overall Score**: [X/100]
           
           ### Key Observations & Missing Elements:
           1. **[Category]**: [Specific finding with **bold** keywords]
           2. **[Category]**: [Specific finding with **bold** keywords]
           3. **[Category]**: [Specific finding with **bold** keywords]
           
           Would you like me to **rebuild** your resume with these improvements?
           ```
        
        RULES:
        - Always use Markdown with **Bold** and ### Headers
        - Be proactive - don't wait for user commands
        - When user says "rebuild" or "yes", immediately call latex_builder_tool with structured JSON
        - Never say "I can help" without showing what you've already found
    """


    real_model = LegacyGemini(
        api_key=GEMINI_API_KEY,
        model="gemini-flash-lite-latest",
        system_instruction=instruction,
        tools=[
            parse_resume_tool,
            semantic_similarity_tool,
            keyword_match_tool,
            ats_checker_tool,
            scoring_tool,
            latex_builder_tool
        ]
    )

    mock_model = MockGemini()
    
    # Use FallbackGemini as the primary model
    model = FallbackGemini(real_model=real_model, mock_model=mock_model)


    agent = Agent(
        name="ResumeAI",
        instruction=instruction,
        model=model,
        tools=[
            parse_resume_tool,
            semantic_similarity_tool,
            keyword_match_tool,
            ats_checker_tool,
            scoring_tool,
            latex_builder_tool
        ]
    )
    
    return agent

